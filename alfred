#!/usr/bin/env bash
set -euo pipefail

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
VENV="${ROOT_DIR}/.venv"
PY="${VENV}/bin/python"

ensure_venv() {
  if [[ ! -x "${PY}" ]]; then
    echo "Alfred: I can't find your Python venv at ${VENV}."
    echo "Run: python -m venv .venv && source .venv/bin/activate && pip install chromadb sentence-transformers watchdog rich requests"
    exit 1
  fi
}

ensure_ollama() {
  if ! curl -s "http://localhost:11434/api/tags" >/dev/null 2>&1; then
    echo "Alfred: Ollama isn't reachable at http://localhost:11434."
    echo "Start it, then try again."
    exit 1
  fi
}

run_cli() {
  (cd "${ROOT_DIR}" && "${PY}" -m alfred_ml.cli "$@")
}


cmd_help() {
  cat <<'EOF'
Alfred ML commands:
  ./alfred                   Launch Interactive TUI (Recommended)
  ./alfred chat              Start chat mode directly
  ./alfred ingest            Index files in ./alfred_docs
  ./alfred watch             Auto-index when files change
  ./alfred ask "question"    Ask a single question
  ./alfred where             Show folders used (docs + db)

Tips:
  - Place your .txt or .md files in ./alfred_docs
  - Run ./alfred ingest to build the database
EOF
}

cmd_where() {
  echo "Docs folder: ${ROOT_DIR}/alfred_docs"
  echo "DB folder:   ${ROOT_DIR}/alfred_db"
}

main() {
  # If no arguments, launch TUI
  if [ $# -eq 0 ]; then
    ensure_venv
    ensure_ollama
    # Call python module without arguments to trigger TUI
    run_cli
    exit 0
  fi

  local cmd="$1"
  shift || true

  case "${cmd}" in
    help|-h|--help) cmd_help ;;
    ingest) ensure_venv; ensure_ollama; run_cli ingest ;;
    watch)  ensure_venv; ensure_ollama; run_cli watch ;;
    ask)    ensure_venv; ensure_ollama; run_cli ask "$@" ;;
    chat)   ensure_venv; ensure_ollama; run_cli chat ;;
    where)  cmd_where ;;
    *)      ensure_venv; ensure_ollama; run_cli "$cmd" "$@" ;;
  esac
}

main "$@"
